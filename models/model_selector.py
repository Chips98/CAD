"""
å¿ƒç†æ¨¡å‹é€‰æ‹©å™¨
æä¾›äº¤äº’å¼çš„æ¨¡å‹é€‰æ‹©ç•Œé¢å’Œé…ç½®ç®¡ç†
"""

import json
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.prompt import Prompt, Confirm

from models.psychological_model_base import (
    PsychologicalModelType, ModelFactory, PsychologicalModelBase
)


class ModelSelector:
    """å¿ƒç†æ¨¡å‹é€‰æ‹©å™¨"""
    
    def __init__(self, console: Console = None):
        """åˆå§‹åŒ–æ¨¡å‹é€‰æ‹©å™¨"""
        self.console = console or Console()
        self.config_file = Path("config/psychological_model_config.json")
        self.config_file.parent.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½é»˜è®¤é…ç½®
        self.default_config = self._load_default_config()
        
        # å½“å‰é€‰æ‹©
        self.selected_model_type = None
        self.selected_config = {}
    
    def _load_default_config(self) -> Dict[str, Any]:
        """åŠ è½½é»˜è®¤é…ç½®"""
        return {
            "default_model": PsychologicalModelType.CAD_ENHANCED.value,
            "model_configs": {
                PsychologicalModelType.BASIC_RULES.value: {
                    "stress_multiplier": 0.5,
                    "self_esteem_multiplier": 0.3,
                    "depression_threshold": 3,
                    "recovery_rate": 0.1,
                    "negative_bias": 1.2
                },
                PsychologicalModelType.CAD_ENHANCED.value: {
                    "belief_impact_strength": 0.4,
                    "affective_amplification": 1.3,
                    "rumination_threshold": 6.0,
                    "cognitive_distortion_rate": 0.1,
                    "daily_decay_rate": 0.04
                },
                PsychologicalModelType.LLM_DRIVEN.value: {
                    "max_retries": 3,
                    "timeout_seconds": 30,
                    "temperature": 0.3,
                    "confidence_threshold": 0.6,
                    "enable_detailed_analysis": True
                },
                PsychologicalModelType.HYBRID.value: {
                    "basic_rules_weight": 0.3,
                    "cad_weight": 0.4,
                    "llm_weight": 0.3,
                    "llm_trigger_threshold": 3,
                    "llm_frequency": 0.5,
                    "enable_adaptive_weights": True
                }
            },
            "performance_settings": {
                "enable_parallel_processing": True,
                "cache_results": True,
                "log_detailed_metrics": False
            }
        }
    
    def load_saved_config(self) -> Dict[str, Any]:
        """åŠ è½½ä¿å­˜çš„é…ç½®"""
        try:
            if self.config_file.exists():
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    saved_config = json.load(f)
                # åˆå¹¶é»˜è®¤é…ç½®
                config = self.default_config.copy()
                config.update(saved_config)
                return config
            else:
                return self.default_config
        except Exception as e:
            self.console.print(f"[yellow]åŠ è½½é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}[/yellow]")
            return self.default_config
    
    def save_config(self, config: Dict[str, Any]):
        """ä¿å­˜é…ç½®"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            self.console.print(f"[green]é…ç½®å·²ä¿å­˜åˆ°: {self.config_file}[/green]")
        except Exception as e:
            self.console.print(f"[red]ä¿å­˜é…ç½®å¤±è´¥: {e}[/red]")
    
    def select_model_interactive(self, ai_client = None) -> Tuple[PsychologicalModelType, Dict[str, Any]]:
        """äº¤äº’å¼é€‰æ‹©å¿ƒç†æ¨¡å‹"""
        
        # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
        self.console.print(Panel(
            "[bold blue]å¿ƒç†æ¨¡å‹é€‰æ‹©å™¨[/bold blue]\n\n"
            "è¯·é€‰æ‹©é€‚åˆæ‚¨éœ€æ±‚çš„å¿ƒç†çŠ¶æ€è¯„ä¼°æ¨¡å‹ã€‚\n"
            "ä¸åŒæ¨¡å‹åœ¨å‡†ç¡®æ€§ã€é€Ÿåº¦å’ŒåŠŸèƒ½ä¸Šå„æœ‰ç‰¹è‰²ã€‚",
            title="ğŸ§  æ¨¡å‹é€‰æ‹©",
            border_style="blue"
        ))
        
        # è·å–å¯ç”¨æ¨¡å‹ä¿¡æ¯
        model_info = ModelFactory.get_model_info_all()
        
        # æ˜¾ç¤ºæ¨¡å‹å¯¹æ¯”è¡¨
        self._display_model_comparison(model_info, ai_client)
        
        # é€‰æ‹©æ¨¡å‹
        selected_type = self._prompt_model_selection(model_info, ai_client)
        
        # é…ç½®æ¨¡å‹å‚æ•°
        config = self._configure_model_parameters(selected_type)
        
        # ç¡®è®¤é€‰æ‹©
        if self._confirm_selection(selected_type, config):
            # ä¿å­˜é…ç½®
            full_config = self.load_saved_config()
            full_config["default_model"] = selected_type.value
            full_config["model_configs"][selected_type.value] = config
            self.save_config(full_config)
            
            self.selected_model_type = selected_type
            self.selected_config = config
            
            return selected_type, config
        else:
            # é‡æ–°é€‰æ‹©
            return self.select_model_interactive(ai_client)
    
    def _display_model_comparison(self, model_info: Dict, ai_client = None):
        """æ˜¾ç¤ºæ¨¡å‹å¯¹æ¯”è¡¨"""
        table = Table(title="ğŸ” å¿ƒç†æ¨¡å‹å¯¹æ¯”")
        table.add_column("æ¨¡å‹", style="cyan", no_wrap=True)
        table.add_column("æè¿°", style="white", width=35)
        table.add_column("CADæ”¯æŒ", justify="center", style="green")
        table.add_column("å¼‚æ­¥å¤„ç†", justify="center", style="yellow")
        table.add_column("AIéœ€æ±‚", justify="center", style="red")
        table.add_column("æ¨èåœºæ™¯", style="blue", width=25)
        
        # æ¨èåœºæ™¯æ˜ å°„
        recommendations = {
            PsychologicalModelType.BASIC_RULES: "å¿«é€Ÿæµ‹è¯•ã€æ•™å­¦æ¼”ç¤º",
            PsychologicalModelType.CAD_ENHANCED: "ç§‘ç ”åˆ†æã€å‡†ç¡®æ¨¡æ‹Ÿ",
            PsychologicalModelType.LLM_DRIVEN: "æ·±åº¦åˆ†æã€å¤æ‚æ¡ˆä¾‹",
            PsychologicalModelType.HYBRID: "ç”Ÿäº§ç¯å¢ƒã€ç»¼åˆè¯„ä¼°"
        }
        
        for model_type, info in model_info.items():
            # æ£€æŸ¥AIå¯ç”¨æ€§
            ai_available = "âœ“" if not info["requires_ai_client"] or ai_client else "âœ—"
            ai_style = "green" if ai_available == "âœ“" else "red"
            
            table.add_row(
                info["display_name"],
                info["description"],
                "âœ“" if info["supports_cad"] else "âœ—",
                "âœ“" if info["supports_async"] else "âœ—",
                f"[{ai_style}]{ai_available}[/{ai_style}]",
                recommendations.get(model_type, "é€šç”¨åœºæ™¯")
            )
        
        self.console.print(table)
    
    def _prompt_model_selection(self, model_info: Dict, ai_client = None) -> PsychologicalModelType:
        """æç¤ºç”¨æˆ·é€‰æ‹©æ¨¡å‹"""
        
        # è¿‡æ»¤å¯ç”¨æ¨¡å‹
        available_models = []
        for model_type, info in model_info.items():
            if not info["requires_ai_client"] or ai_client:
                available_models.append(model_type)
        
        if not available_models:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„å¿ƒç†æ¨¡å‹")
        
        # æ˜¾ç¤ºé€‰æ‹©èœå•
        self.console.print("\n[cyan]å¯ç”¨æ¨¡å‹ï¼š[/cyan]")
        for i, model_type in enumerate(available_models, 1):
            info = model_info[model_type]
            self.console.print(f"  {i}. {info['display_name']}")
        
        # è·å–ç”¨æˆ·é€‰æ‹©
        while True:
            try:
                choice = Prompt.ask(
                    "\nè¯·é€‰æ‹©æ¨¡å‹",
                    choices=[str(i) for i in range(1, len(available_models) + 1)],
                    default="2"  # é»˜è®¤é€‰æ‹©CADå¢å¼ºæ¨¡å‹
                )
                
                selected_index = int(choice) - 1
                selected_type = available_models[selected_index]
                
                # æ˜¾ç¤ºé€‰æ‹©çš„æ¨¡å‹ä¿¡æ¯
                info = model_info[selected_type]
                self.console.print(f"\n[green]å·²é€‰æ‹©: {info['display_name']}[/green]")
                self.console.print(f"[dim]{info['description']}[/dim]")
                
                return selected_type
                
            except (ValueError, IndexError):
                self.console.print("[red]æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥[/red]")
    
    def _configure_model_parameters(self, model_type: PsychologicalModelType) -> Dict[str, Any]:
        """é…ç½®æ¨¡å‹å‚æ•°"""
        
        # è·å–é»˜è®¤é…ç½®
        default_config = self.default_config["model_configs"].get(model_type.value, {})
        
        # è¯¢é—®æ˜¯å¦è‡ªå®šä¹‰é…ç½®
        if not Confirm.ask("\næ˜¯å¦è‡ªå®šä¹‰æ¨¡å‹å‚æ•°", default=False):
            return default_config
        
        self.console.print(f"\n[cyan]é…ç½® {model_type.value} æ¨¡å‹å‚æ•°ï¼š[/cyan]")
        
        config = {}
        parameter_descriptions = self._get_parameter_descriptions(model_type)
        
        for param_name, default_value in default_config.items():
            description = parameter_descriptions.get(param_name, "")
            
            # æ˜¾ç¤ºå‚æ•°ä¿¡æ¯
            self.console.print(f"\n[white]{param_name}[/white]: {description}")
            self.console.print(f"[dim]é»˜è®¤å€¼: {default_value}[/dim]")
            
            # è·å–ç”¨æˆ·è¾“å…¥
            if isinstance(default_value, bool):
                config[param_name] = Confirm.ask("æ˜¯å¦å¯ç”¨", default=default_value)
            elif isinstance(default_value, (int, float)):
                while True:
                    try:
                        user_input = Prompt.ask(
                            "è¯·è¾“å…¥æ•°å€¼",
                            default=str(default_value)
                        )
                        config[param_name] = type(default_value)(user_input)
                        break
                    except ValueError:
                        self.console.print("[red]è¯·è¾“å…¥æœ‰æ•ˆæ•°å€¼[/red]")
            else:
                config[param_name] = Prompt.ask(
                    "è¯·è¾“å…¥å€¼",
                    default=str(default_value)
                )
        
        return config
    
    def _get_parameter_descriptions(self, model_type: PsychologicalModelType) -> Dict[str, str]:
        """è·å–å‚æ•°æè¿°"""
        descriptions = {
            PsychologicalModelType.BASIC_RULES: {
                "stress_multiplier": "å‹åŠ›å½±å“å€æ•° (0.1-1.0)",
                "self_esteem_multiplier": "è‡ªå°Šå½±å“å€æ•° (0.1-1.0)",
                "depression_threshold": "æŠ‘éƒæ£€æµ‹é˜ˆå€¼ (1-10)",
                "recovery_rate": "è‡ªç„¶æ¢å¤é€Ÿç‡ (0.01-0.5)",
                "negative_bias": "è´Ÿé¢åå·®å€æ•° (1.0-2.0)"
            },
            PsychologicalModelType.CAD_ENHANCED: {
                "belief_impact_strength": "ä¿¡å¿µå½±å“å¼ºåº¦ (0.1-1.0)",
                "affective_amplification": "æƒ…æ„Ÿæ”¾å¤§ç³»æ•° (1.0-2.0)",
                "rumination_threshold": "æ€ç»´ååˆé˜ˆå€¼ (3.0-10.0)",
                "cognitive_distortion_rate": "è®¤çŸ¥æ‰­æ›²å¢é•¿ç‡ (0.01-0.5)",
                "daily_decay_rate": "æ¯æ—¥è¡°å‡ç‡ (0.01-0.1)"
            },
            PsychologicalModelType.LLM_DRIVEN: {
                "max_retries": "æœ€å¤§é‡è¯•æ¬¡æ•° (1-10)",
                "timeout_seconds": "è¶…æ—¶æ—¶é—´ç§’æ•° (10-60)",
                "temperature": "LLMæ¸©åº¦å‚æ•° (0.0-1.0)",
                "confidence_threshold": "ç½®ä¿¡åº¦é˜ˆå€¼ (0.1-1.0)",
                "enable_detailed_analysis": "å¯ç”¨è¯¦ç»†åˆ†æ"
            },
            PsychologicalModelType.HYBRID: {
                "basic_rules_weight": "åŸºç¡€è§„åˆ™æƒé‡ (0.0-1.0)",
                "cad_weight": "CADæ¨¡å‹æƒé‡ (0.0-1.0)", 
                "llm_weight": "LLMæ¨¡å‹æƒé‡ (0.0-1.0)",
                "llm_trigger_threshold": "LLMè§¦å‘é˜ˆå€¼ (1-10)",
                "llm_frequency": "LLMä½¿ç”¨é¢‘ç‡ (0.0-1.0)",
                "enable_adaptive_weights": "å¯ç”¨è‡ªé€‚åº”æƒé‡"
            }
        }
        
        return descriptions.get(model_type, {})
    
    def _confirm_selection(self, model_type: PsychologicalModelType, config: Dict[str, Any]) -> bool:
        """ç¡®è®¤é€‰æ‹©"""
        
        # æ˜¾ç¤ºæœ€ç»ˆé…ç½®
        self.console.print(Panel(
            f"[bold]æ¨¡å‹ç±»å‹:[/bold] {model_type.value}\n"
            f"[bold]é…ç½®å‚æ•°:[/bold]\n" +
            "\n".join([f"  {k}: {v}" for k, v in config.items()]),
            title="ğŸ“‹ é…ç½®ç¡®è®¤",
            border_style="green"
        ))
        
        return Confirm.ask("\nç¡®è®¤ä½¿ç”¨æ­¤é…ç½®", default=True)
    
    def quick_select(self, model_name: str = None, ai_client = None) -> Tuple[PsychologicalModelType, Dict[str, Any]]:
        """å¿«é€Ÿé€‰æ‹©æ¨¡å‹ï¼ˆç”¨äºè„šæœ¬è°ƒç”¨ï¼‰"""
        
        # åŠ è½½é…ç½®
        config = self.load_saved_config()
        
        # ç¡®å®šæ¨¡å‹ç±»å‹
        if model_name:
            try:
                model_type = PsychologicalModelType(model_name)
            except ValueError:
                self.console.print(f"[red]æ— æ•ˆçš„æ¨¡å‹åç§°: {model_name}[/red]")
                model_type = PsychologicalModelType(config["default_model"])
        else:
            model_type = PsychologicalModelType(config["default_model"])
        
        # æ£€æŸ¥AIå®¢æˆ·ç«¯éœ€æ±‚
        model_info = ModelFactory.get_model_info_all()
        if model_info[model_type]["requires_ai_client"] and not ai_client:
            self.console.print(f"[yellow]æ¨¡å‹ {model_type.value} éœ€è¦AIå®¢æˆ·ç«¯ï¼Œå›é€€åˆ°CADæ¨¡å‹[/yellow]")
            model_type = PsychologicalModelType.CAD_ENHANCED
        
        # è·å–æ¨¡å‹é…ç½®
        model_config = config["model_configs"].get(model_type.value, {})
        
        self.console.print(f"[green]ä½¿ç”¨å¿ƒç†æ¨¡å‹: {model_type.value}[/green]")
        
        return model_type, model_config
    
    def create_model_instance(self, 
                            model_type: PsychologicalModelType, 
                            config: Dict[str, Any],
                            ai_client = None) -> PsychologicalModelBase:
        """åˆ›å»ºæ¨¡å‹å®ä¾‹"""
        try:
            return ModelFactory.create_model(model_type, config, ai_client)
        except Exception as e:
            self.console.print(f"[red]åˆ›å»ºæ¨¡å‹å®ä¾‹å¤±è´¥: {e}[/red]")
            # å›é€€åˆ°åŸºç¡€è§„åˆ™æ¨¡å‹
            self.console.print("[yellow]å›é€€åˆ°åŸºç¡€è§„åˆ™æ¨¡å‹[/yellow]")
            return ModelFactory.create_model(PsychologicalModelType.BASIC_RULES, {})
    
    def display_model_statistics(self, model: PsychologicalModelBase):
        """æ˜¾ç¤ºæ¨¡å‹ç»Ÿè®¡ä¿¡æ¯"""
        info = model.get_model_info()
        stats = info["statistics"]
        
        table = Table(title=f"ğŸ“Š {info['type']} æ¨¡å‹ç»Ÿè®¡")
        table.add_column("æŒ‡æ ‡", style="cyan")
        table.add_column("æ•°å€¼", style="yellow", justify="right")
        
        table.add_row("æ€»è®¡ç®—æ¬¡æ•°", str(stats["total_calculations"]))
        table.add_row("å¹³å‡å¤„ç†æ—¶é—´", f"{stats['average_processing_time']:.2f}ms")
        table.add_row("é”™è¯¯ç‡", f"{stats['error_rate']:.1%}")
        table.add_row("CADæ”¯æŒ", "âœ“" if info["supports_cad"] else "âœ—")
        table.add_row("å¼‚æ­¥æ”¯æŒ", "âœ“" if info["supports_async"] else "âœ—")
        
        self.console.print(table)